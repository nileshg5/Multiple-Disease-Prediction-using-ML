# -*- coding: utf-8 -*-
"""Project 4: Parkinson's Disease Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14R0gf14X4xNZOLwxqxCtEQMkLgyCdzkA

Importing the Dependencies
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn import svm
from sklearn.metrics import accuracy_score
import warnings
warnings.filterwarnings('ignore')

"""**About Dataset**

Title: Parkinsons Disease Data Set

Abstract: Oxford Parkinson's Disease Detection Dataset

Number of Instances: 197
Number of Attributes: 23
Associated Tasks: Classification

Source:

The dataset was created by Max Little of the University of Oxford, in
collaboration with the National Centre for Voice and Speech, Denver,
Colorado, who recorded the speech signals. The original study published the
feature extraction methods for general voice disorders.

Data Set Information:

This dataset is composed of a range of biomedical voice measurements from
31 people, 23 with Parkinson's disease (PD). Each column in the table is a
particular voice measure, and each row corresponds one of 195 voice
recording from these individuals ("name" column). The main aim of the data
is to discriminate healthy people from those with PD, according to "status"
column which is set to 0 for healthy and 1 for PD.

**Attribute Information:**

Matrix column entries (attributes):

colums        | Description
--------------|------------
name          | ASCII subject name and recording number
MDVP:Fo(Hz)   | Average vocal fundamental frequency
MDVP:Fhi(Hz)  | Maximum vocal fundamental frequency
MDVP:Flo(Hz)  | Minimum vocal fundamental frequency
MDVP:Jitter(%),MDVP:Jitter(Abs),MDVP:RAP,MDVP:PPQ,Jitter:DDP | Several measures of variation in fundamental frequency
MDVP:Shimmer,MDVP:Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,MDVP:APQ,Shimmer:DDA   | Several measures of variation in amplitude
NHR,HNR       | Two measures of ratio of noise to tonal components in the voice
status        | Health status of the subject (one) - Parkinson's, (zero) - healthy
RPDE,D2       | Two nonlinear dynamical complexity measures
DFA           | Signal fractal scaling exponent
spread1,spread2,PPE | Three nonlinear measures of fundamental frequency variation
"""

from google.colab import drive
drive.mount('/content/drive')

"""Data Collection & Analysis"""

# loading the data from csv file to a Pandas DataFrame
parkinsons_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/parkinsons.csv')

# printing the first 5 rows of the dataframe
parkinsons_data.head()

# number of rows and columns in the dataframe
parkinsons_data.shape

# getting more information about the dataset
parkinsons_data.info()

# checking for missing values in each column
parkinsons_data.isnull().sum()

# getting some statistical measures about the data
parkinsons_data.describe()

# distribution of target Variable
parkinsons_data['status'].value_counts()

"""1  --> Parkinson's Positive

0 --> Healthy

"""

# grouping the data bas3ed on the target variable
df = parkinsons_data.drop('name', axis=1)
df = df.groupby('status').mean()
df

"""Data Pre-Processing

Separating the features & Target
"""

X = parkinsons_data.drop(columns=['name','status'], axis=1)
Y = parkinsons_data['status']

print(X)

print(Y)

"""Splitting the data to training data & Test data"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, stratify = Y, random_state=2)

print(X.shape, X_train.shape, X_test.shape)

"""Data Standardization"""

scaler = StandardScaler()

scaler.fit(X_train)

X_train = scaler.transform(X_train)

X_test = scaler.transform(X_test)

print(X_train)

"""Model Training

*Logistic Regression*
"""

model = LogisticRegression()

# training the LogisticRegression model with Training data
model.fit(X_train, Y_train)

"""Support Vector Machine Model"""

model_svm = svm.SVC(kernel='linear')

# training the SVM model with training data
model_svm.fit(X_train, Y_train)

"""Model Evaluation

Accuracy Score
"""

# accuracy on training data in Logistic Regression
X_train_prediction = model.predict(X_train)
training_data_accuracy = accuracy_score(X_train_prediction, Y_train)

print('Accuracy on Training data : ', training_data_accuracy)

# accuracy on test data in Logistic Regression
X_test_prediction = model.predict(X_test)
test_data_accuracy = accuracy_score(X_test_prediction, Y_test)

print('Accuracy on Test data : ', test_data_accuracy)

# accuracy score on training data in svm
X_train_prediction_svm = model_svm.predict(X_train)
training_data_accuracy_svm = accuracy_score(Y_train, X_train_prediction_svm)

print('Accuracy score of training data : ', training_data_accuracy_svm)

# accuracy score on testing data in svm
X_test_prediction_svm = model_svm.predict(X_test)
test_data_accuracy_svm = accuracy_score(Y_test, X_test_prediction_svm)

print('Accuracy score of test data : ', test_data_accuracy_svm)

"""Building a Predictive System"""

input_data = (180.97800,200.12500,155.49500,0.00406,0.00002,0.00220,0.00244,0.00659,0.03852,0.33100,0.02107,0.02493,0.02877,0.06321,0.02782,16.17600,0.583574,0.727747,-5.657899,0.315903,3.098256,0.200423)

# changing input data to a numpy array
input_data_as_numpy_array = np.asarray(input_data)

# reshape the numpy array
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

# standardize the data
std_data = scaler.transform(input_data_reshaped)

prediction = model_svm.predict(std_data)
print(prediction)


if (prediction[0] == 0):
  print("The Person does not have Parkinsons Disease")

else:
  print("The Person has Parkinsons")

import pickle
with open('parkinsons_model.pkl',  'wb') as file:
  pickle.dump(model_svm, file)